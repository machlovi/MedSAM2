{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Video Segmentation with MedSAM2\n",
    "This notebook shows how to use MedSAM2 for video segmentation inference. \n",
    "\n",
    "If running locally using jupyter, first install `MedSAM2` in your environment using the [installation instructions](https://github.com/bowang-lab/MedSAM2?tab=readme-ov-file#installation) in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages and MedsSAM2 video predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "\n",
    "# helper functions\n",
    "DAVIS_PALETTE = b\"\\x00\\x00\\x00\\x80\\x00\\x00\\x00\\x80\\x00\\x80\\x80\\x00\\x00\\x00\\x80\\x80\\x00\\x80\\x00\\x80\\x80\\x80\\x80\\x80@\\x00\\x00\\xc0\\x00\\x00@\\x80\\x00\\xc0\\x80\\x00@\\x00\\x80\\xc0\\x00\\x80@\\x80\\x80\\xc0\\x80\\x80\\x00@\\x00\\x80@\\x00\\x00\\xc0\\x00\\x80\\xc0\\x00\\x00@\\x80\\x80@\\x80\\x00\\xc0\\x80\\x80\\xc0\\x80@@\\x00\\xc0@\\x00@\\xc0\\x00\\xc0\\xc0\\x00@@\\x80\\xc0@\\x80@\\xc0\\x80\\xc0\\xc0\\x80\\x00\\x00@\\x80\\x00@\\x00\\x80@\\x80\\x80@\\x00\\x00\\xc0\\x80\\x00\\xc0\\x00\\x80\\xc0\\x80\\x80\\xc0@\\x00@\\xc0\\x00@@\\x80@\\xc0\\x80@@\\x00\\xc0\\xc0\\x00\\xc0@\\x80\\xc0\\xc0\\x80\\xc0\\x00@@\\x80@@\\x00\\xc0@\\x80\\xc0@\\x00@\\xc0\\x80@\\xc0\\x00\\xc0\\xc0\\x80\\xc0\\xc0@@@\\xc0@@@\\xc0@\\xc0\\xc0@@@\\xc0\\xc0@\\xc0@\\xc0\\xc0\\xc0\\xc0\\xc0 \\x00\\x00\\xa0\\x00\\x00 \\x80\\x00\\xa0\\x80\\x00 \\x00\\x80\\xa0\\x00\\x80 \\x80\\x80\\xa0\\x80\\x80`\\x00\\x00\\xe0\\x00\\x00`\\x80\\x00\\xe0\\x80\\x00`\\x00\\x80\\xe0\\x00\\x80`\\x80\\x80\\xe0\\x80\\x80 @\\x00\\xa0@\\x00 \\xc0\\x00\\xa0\\xc0\\x00 @\\x80\\xa0@\\x80 \\xc0\\x80\\xa0\\xc0\\x80`@\\x00\\xe0@\\x00`\\xc0\\x00\\xe0\\xc0\\x00`@\\x80\\xe0@\\x80`\\xc0\\x80\\xe0\\xc0\\x80 \\x00@\\xa0\\x00@ \\x80@\\xa0\\x80@ \\x00\\xc0\\xa0\\x00\\xc0 \\x80\\xc0\\xa0\\x80\\xc0`\\x00@\\xe0\\x00@`\\x80@\\xe0\\x80@`\\x00\\xc0\\xe0\\x00\\xc0`\\x80\\xc0\\xe0\\x80\\xc0 @@\\xa0@@ \\xc0@\\xa0\\xc0@ @\\xc0\\xa0@\\xc0 \\xc0\\xc0\\xa0\\xc0\\xc0`@@\\xe0@@`\\xc0@\\xe0\\xc0@`@\\xc0\\xe0@\\xc0`\\xc0\\xc0\\xe0\\xc0\\xc0\\x00 \\x00\\x80 \\x00\\x00\\xa0\\x00\\x80\\xa0\\x00\\x00 \\x80\\x80 \\x80\\x00\\xa0\\x80\\x80\\xa0\\x80@ \\x00\\xc0 \\x00@\\xa0\\x00\\xc0\\xa0\\x00@ \\x80\\xc0 \\x80@\\xa0\\x80\\xc0\\xa0\\x80\\x00`\\x00\\x80`\\x00\\x00\\xe0\\x00\\x80\\xe0\\x00\\x00`\\x80\\x80`\\x80\\x00\\xe0\\x80\\x80\\xe0\\x80@`\\x00\\xc0`\\x00@\\xe0\\x00\\xc0\\xe0\\x00@`\\x80\\xc0`\\x80@\\xe0\\x80\\xc0\\xe0\\x80\\x00 @\\x80 @\\x00\\xa0@\\x80\\xa0@\\x00 \\xc0\\x80 \\xc0\\x00\\xa0\\xc0\\x80\\xa0\\xc0@ @\\xc0 @@\\xa0@\\xc0\\xa0@@ \\xc0\\xc0 \\xc0@\\xa0\\xc0\\xc0\\xa0\\xc0\\x00`@\\x80`@\\x00\\xe0@\\x80\\xe0@\\x00`\\xc0\\x80`\\xc0\\x00\\xe0\\xc0\\x80\\xe0\\xc0@`@\\xc0`@@\\xe0@\\xc0\\xe0@@`\\xc0\\xc0`\\xc0@\\xe0\\xc0\\xc0\\xe0\\xc0  \\x00\\xa0 \\x00 \\xa0\\x00\\xa0\\xa0\\x00  \\x80\\xa0 \\x80 \\xa0\\x80\\xa0\\xa0\\x80` \\x00\\xe0 \\x00`\\xa0\\x00\\xe0\\xa0\\x00` \\x80\\xe0 \\x80`\\xa0\\x80\\xe0\\xa0\\x80 `\\x00\\xa0`\\x00 \\xe0\\x00\\xa0\\xe0\\x00 `\\x80\\xa0`\\x80 \\xe0\\x80\\xa0\\xe0\\x80``\\x00\\xe0`\\x00`\\xe0\\x00\\xe0\\xe0\\x00``\\x80\\xe0`\\x80`\\xe0\\x80\\xe0\\xe0\\x80  @\\xa0 @ \\xa0@\\xa0\\xa0@  \\xc0\\xa0 \\xc0 \\xa0\\xc0\\xa0\\xa0\\xc0` @\\xe0 @`\\xa0@\\xe0\\xa0@` \\xc0\\xe0 \\xc0`\\xa0\\xc0\\xe0\\xa0\\xc0 `@\\xa0`@ \\xe0@\\xa0\\xe0@ `\\xc0\\xa0`\\xc0 \\xe0\\xc0\\xa0\\xe0\\xc0``@\\xe0`@`\\xe0@\\xe0\\xe0@``\\xc0\\xe0`\\xc0`\\xe0\\xc0\\xe0\\xe0\\xc0\"\n",
    "\n",
    "def load_ann_png(path):\n",
    "    \"\"\"Load a PNG file as a mask and its palette.\"\"\"\n",
    "    mask = Image.open(path)\n",
    "    palette = mask.getpalette()\n",
    "    mask = np.array(mask).astype(np.uint8)\n",
    "    return mask, palette\n",
    "\n",
    "def get_per_obj_mask(mask):\n",
    "    \"\"\"Split a mask into per-object masks.\"\"\"\n",
    "    object_ids = np.unique(mask)\n",
    "    object_ids = object_ids[object_ids > 0].tolist()\n",
    "    per_obj_mask = {object_id: (mask == object_id) for object_id in object_ids}\n",
    "    return per_obj_mask\n",
    "\n",
    "def put_per_obj_mask(per_obj_mask, height, width):\n",
    "    \"\"\"Combine per-object masks into a single mask.\"\"\"\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    object_ids = sorted(per_obj_mask)[::-1]\n",
    "    for object_id in object_ids:\n",
    "        object_mask = per_obj_mask[object_id]\n",
    "        object_mask = object_mask.reshape(height, width)\n",
    "        mask[object_mask] = object_id\n",
    "    return mask\n",
    "\n",
    "def load_masks_from_dir(input_mask_path):\n",
    "    input_mask, input_palette = load_ann_png(input_mask_path)\n",
    "    per_obj_input_mask = get_per_obj_mask(input_mask)\n",
    "\n",
    "    return per_obj_input_mask, input_palette\n",
    "\n",
    "def save_predictions_to_dir(\n",
    "    output_mask_dir,\n",
    "    video_name,\n",
    "    frame_name,\n",
    "    per_obj_output_mask,\n",
    "    height,\n",
    "    width,\n",
    "):\n",
    "    \"\"\"Save masks to a directory as PNG files.\"\"\"\n",
    "    os.makedirs(os.path.join(output_mask_dir, video_name), exist_ok=True)\n",
    "\n",
    "    output_mask = put_per_obj_mask(per_obj_output_mask, height, width)\n",
    "    output_mask_path = os.path.join(\n",
    "        output_mask_dir, video_name, f\"{frame_name}.png\"\n",
    "    )\n",
    "    assert output_mask.dtype == np.uint8\n",
    "    assert output_mask.ndim == 2\n",
    "    output_mask = Image.fromarray(output_mask)\n",
    "    output_mask.save(output_mask_path)\n",
    "\n",
    "def create_overlay(img_path, mask_path, palette):\n",
    "    \"\"\"Create an overlay of an image and a mask.\"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    mask = Image.open(mask_path)\n",
    "    mask.putpalette(palette)\n",
    "    mask_rgb = mask.convert(\"RGB\")\n",
    "    mask_rgb = mask_rgb.resize(img.size, Image.NEAREST)\n",
    "    overlay = Image.blend(img, mask_rgb, alpha=0.5)\n",
    "    return overlay\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to customized path\n",
    "VIDEO_DIR = \"/media/jma/MyPassport/MedSAM2/datasets/Demo/images\"\n",
    "VIDEO_NAME = \"patient0213_4CH\"\n",
    "INITIAL_MASK_PROMPT = \"/media/jma/MyPassport/MedSAM2/datasets/Demo/masks/patient0213_4CH/patient0213_4CH_half_sequence-000.png\"\n",
    "OUTPUT_DIR = \"/media/jma/MyPassport/MedSAM2/datasets/Demo/output\"\n",
    "\n",
    "MODEL_CONFIG = \"configs/sam2.1_hiera_t512.yaml\"\n",
    "MODEL_CHECKPOINT = \"checkpoints/MedSAM2_latest.pt\"\n",
    "\n",
    "predictor = build_sam2_video_predictor(\n",
    "    config_file=MODEL_CONFIG,\n",
    "    ckpt_path=MODEL_CHECKPOINT,\n",
    "    apply_postprocessing=True,\n",
    "    # hydra_overrides_extra=hydra_overrides_extra,\n",
    "    vos_optimized=  True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Inference and Add Initial Mask Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/jma/MyPassport/MedSAM2/datasets/Demo/images/patient0213_4CH'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load the video frames\u001b[39;00m\n\u001b[32m      2\u001b[39m frame_names = [\n\u001b[32m      3\u001b[39m         os.path.splitext(p)[\u001b[32m0\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVIDEO_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVIDEO_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m os.path.splitext(p)[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.jpeg\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.JPG\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.JPEG\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m     ]\n\u001b[32m      7\u001b[39m frame_names = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(frame_names))\n\u001b[32m      8\u001b[39m inference_state = predictor.init_state(\n\u001b[32m      9\u001b[39m     video_path=os.path.join(VIDEO_DIR, VIDEO_NAME), async_loading_frames=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/media/jma/MyPassport/MedSAM2/datasets/Demo/images/patient0213_4CH'"
     ]
    }
   ],
   "source": [
    "# load the video frames\n",
    "frame_names = [\n",
    "        os.path.splitext(p)[0]\n",
    "        for p in os.listdir(os.path.join(VIDEO_DIR, VIDEO_NAME))\n",
    "        if os.path.splitext(p)[-1] in [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\"]\n",
    "    ]\n",
    "frame_names = list(sorted(frame_names))\n",
    "inference_state = predictor.init_state(\n",
    "    video_path=os.path.join(VIDEO_DIR, VIDEO_NAME), async_loading_frames=False\n",
    ")\n",
    "height = inference_state[\"video_height\"]\n",
    "width = inference_state[\"video_width\"]\n",
    "input_palette = None\n",
    "\n",
    "# Add input masks to MedSAM2 inference state before propagation\n",
    "object_ids_set = None\n",
    "input_frame_idx = 0  # use first frame as mask input\n",
    "try:\n",
    "    per_obj_input_mask, input_palette = load_masks_from_dir(input_mask_path=INITIAL_MASK_PROMPT)\n",
    "except FileNotFoundError as e:\n",
    "    raise RuntimeError(\n",
    "        f\"In {VIDEO_NAME=}, failed to load input mask for frame {input_frame_idx=}. \"\n",
    "        \"Please add the `--track_object_appearing_later_in_video` flag \"\n",
    "        \"for VOS datasets that don't have all objects to track appearing \"\n",
    "        \"in the first frame (such as LVOS or YouTube-VOS).\"\n",
    "    ) from e\n",
    "\n",
    "# get the list of object ids to track from the first input frame\n",
    "if object_ids_set is None:\n",
    "    object_ids_set = set(per_obj_input_mask)\n",
    "for object_id, object_mask in per_obj_input_mask.items():\n",
    "    # check and make sure no new object ids appear only in later frames\n",
    "    if object_id not in object_ids_set:\n",
    "        raise RuntimeError(\n",
    "            f\"In {VIDEO_NAME=}, got a new {object_id=} appearing only in a \"\n",
    "            f\"later {input_frame_idx=} (but not appearing in the first frame). \"\n",
    "            \"Please add the `--track_object_appearing_later_in_video` flag \"\n",
    "            \"for VOS datasets that don't have all objects to track appearing \"\n",
    "            \"in the first frame (such as LVOS or YouTube-VOS).\"\n",
    "        )\n",
    "    predictor.add_new_mask(\n",
    "        inference_state=inference_state,\n",
    "        frame_idx=input_frame_idx,\n",
    "        obj_id=object_id,\n",
    "        mask=object_mask,\n",
    "            )\n",
    "    \n",
    "# check and make sure we have at least one object to track\n",
    "if object_ids_set is None or len(object_ids_set) == 0:\n",
    "    raise RuntimeError(\n",
    "        f\"In {VIDEO_NAME=}, got no object ids on {input_frame_idx=}. \"\n",
    "        \"Please add the `--track_object_appearing_later_in_video` flag \"\n",
    "        \"for VOS datasets that don't have all objects to track appearing \"\n",
    "        \"in the first frame (such as LVOS or YouTube-VOS).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/media/jma'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# run propagation throughout the video\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVIDEO_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m video_segments = {}  \u001b[38;5;66;03m# Store the per-frame segmentation results\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m out_frame_idx, out_obj_ids, out_mask_logits \u001b[38;5;129;01min\u001b[39;00m predictor.propagate_in_video(\n\u001b[32m      6\u001b[39m     inference_state\n\u001b[32m      7\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/data/arsoyd01lab/machlm03/.conda/envs/medsam2/lib/python3.12/os.py:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path.exists(head):\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[32m    217\u001b[39m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[32m    218\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/data/arsoyd01lab/machlm03/.conda/envs/medsam2/lib/python3.12/os.py:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path.exists(head):\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[32m    217\u001b[39m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[32m    218\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: makedirs at line 215 (3 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/data/arsoyd01lab/machlm03/.conda/envs/medsam2/lib/python3.12/os.py:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path.exists(head):\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[32m    217\u001b[39m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[32m    218\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gpfs/data/arsoyd01lab/machlm03/.conda/envs/medsam2/lib/python3.12/os.py:225\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n\u001b[32m    223\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path.isdir(name):\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/media/jma'"
     ]
    }
   ],
   "source": [
    "# run propagation throughout the video\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, VIDEO_NAME), exist_ok=True)\n",
    "\n",
    "video_segments = {}  # Store the per-frame segmentation results\n",
    "for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(\n",
    "    inference_state\n",
    "):\n",
    "    per_obj_output_mask = {\n",
    "        out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "        for i, out_obj_id in enumerate(out_obj_ids)\n",
    "    }\n",
    "    video_segments[out_frame_idx] = per_obj_output_mask\n",
    "\n",
    "# write the output masks\n",
    "for out_frame_idx, per_obj_output_mask in video_segments.items():\n",
    "    # save raw prediction results\n",
    "    save_predictions_to_dir(\n",
    "        output_mask_dir=OUTPUT_DIR,\n",
    "        video_name=VIDEO_NAME,\n",
    "        frame_name=frame_names[out_frame_idx],\n",
    "        per_obj_output_mask=per_obj_output_mask,\n",
    "        height=height,\n",
    "        width=width,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Inference Results\n",
    "Visualize segmentation results for 3 key frames at the 25%, 50%, and 75% position in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_palette' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m output_palette = \u001b[43minput_palette\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m DAVIS_PALETTE\n\u001b[32m      2\u001b[39m images = \u001b[38;5;28msorted\u001b[39m(os.listdir(os.path.join(VIDEO_DIR, VIDEO_NAME)))\n\u001b[32m      3\u001b[39m masks = \u001b[38;5;28msorted\u001b[39m(os.listdir(os.path.join(OUTPUT_DIR, VIDEO_NAME)))\n",
      "\u001b[31mNameError\u001b[39m: name 'input_palette' is not defined"
     ]
    }
   ],
   "source": [
    "output_palette = input_palette or DAVIS_PALETTE\n",
    "images = sorted(os.listdir(os.path.join(VIDEO_DIR, VIDEO_NAME)))\n",
    "masks = sorted(os.listdir(os.path.join(OUTPUT_DIR, VIDEO_NAME)))\n",
    "num_frames = len(images)\n",
    "selected_indices = [int(num_frames * 0.25), int(num_frames * 0.5), int(num_frames * 0.75)]\n",
    "selected_frames = [(images[i], masks[i]) for i in selected_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for idx, (img, mask) in enumerate(selected_frames):\n",
    "    overlay = create_overlay(os.path.join(VIDEO_DIR, VIDEO_NAME, img), os.path.join(OUTPUT_DIR, VIDEO_NAME, mask), output_palette)\n",
    "\n",
    "    plt.subplot(1, 3, idx + 1)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(f\"Frame {int(num_frames*0.25*(idx+1))}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsam2",
   "language": "python",
   "name": "medsam2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
